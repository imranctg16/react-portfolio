# PLG stack

# From Chaos to Clarity: How We Tamed Our Microservice Logs with PLG Stack

*A journey of implementing centralized logging in a Laravel-based microservice architecture*

---

## The Challenge: When Logs Are Everywhere and Nowhere

Picture this: It's 2 AM, your ticket service is acting up, and you're frantically SSH-ing into multiple containers, running `tail -f` commands, and trying to piece together what went wrong. Sound familiar?

In our DWE (Digital Workflow Engine) microservice architecture, we had **11 independent services** running in Docker containers. Each service was generating its own logs, in its own format, stored in its own little silo. When something went wrong (and it always did at the worst possible time), debugging felt like being a detective with half the evidence missing.

**The pain points were real:**

- **Log hunting across multiple containers** - "Was it the gateway? The user service? Or maybe the ticket service?"
- **No unified view** - Each service told only part of the story
- **Time-consuming troubleshooting** - Hours spent connecting dots across different log files
- **Reactive monitoring** - We only knew about problems when users started complaining

## The Solution: Enter the PLG Stack

After researching various logging solutions, we decided to implement the **PLG stack** - a powerful combination of:

- **Prometheus** - Metrics collection (though we focused on the "LG" part for now)
- **Loki** - Log aggregation and storage
- **Grafana** - Visualization and alerting

Why PLG? Unlike traditional logging solutions that require complex setup and licensing costs, the PLG stack is:

- **Open source** and free
- **Designed for cloud-native** environments
- **Horizontally scalable**
- **Plays well with Docker**

## What We Built: A Centralized Logging Paradise

### Architecture Overview

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Ticket Service │    │   User Service  │    │  Gateway Service│
│                 │    │                 │    │                 │
│  Laravel Logs   │    │  Laravel Logs   │    │  Laravel Logs   │
└─────────┬───────┘    └─────────┬───────┘    └─────────┬───────┘
          │                      │                      │
          ▼                      ▼                      ▼
┌─────────────────────────────────────────────────────────────────┐
│                    Promtail (Log Collector)                    │
├─────────────────────────────────────────────────────────────────┤
│                      Loki (Log Storage)                        │
├─────────────────────────────────────────────────────────────────┤
│                    Grafana (Visualization)                     │
└─────────────────────────────────────────────────────────────────┘

```

### The Implementation Journey

### Step 1: Enhanced Laravel Logging

First, we supercharged our Laravel logging configuration. We created a new `centralized` logging channel that outputs structured JSON logs:

```php
'centralized' => [
    'driver' => 'monolog',
    'formatter' => Monolog\\Formatter\\JsonFormatter::class,
    'processors' => [
        function ($record) {
            $record['extra']['service'] = 'ticket-service';
            $record['extra']['version'] = config('app.version', '1.0.0');
            $record['extra']['environment'] = config('app.env');

            // Add correlation ID for request tracing
            if (request()->hasHeader('X-Correlation-ID')) {
                $record['extra']['correlation_id'] = request()->header('X-Correlation-ID');
            }

            return $record;
        },
    ],
],

```

**Why structured JSON?** Because when Loki ingests these logs, it can automatically parse and index all the metadata, making searches lightning-fast.

### Step 2: Docker Integration Magic

We enhanced our `docker-compose.yml` to include proper labeling for log collection:

```yaml
services:
  php:
    build: ./docker/php/
    labels:
      - "service=ticket-service"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

```

These labels help Promtail identify and route logs from different services.

### Step 3: The PLG Stack Deployment

The magic happens in our `docker-commons` setup:

- **Loki** runs on port 3100, acting as our log database
- **Grafana** runs on port 3001, providing beautiful dashboards
- **Promtail** silently collects logs from all our containers

## The Results: From Hours to Seconds

### What We Achieved

**Before PLG:**

- **30+ minutes** to trace an issue across services
- **Manual log correlation** - copying timestamps and request IDs
- **Reactive debugging** - only after user complaints

**After PLG:**

- **30 seconds** to identify the root cause
- **Single query** to search across all services
- **Proactive monitoring** with real-time alerts

### Real-World Impact

1. **Correlation IDs in Action**: When a user reports a ticket creation issue, we can now:
    
    ```
    {service="ticket-service"} |= "correlation_id: abc-123"
    
    ```
    
    And see the entire request flow across gateway → user service → ticket service.
    
2. **Error Pattern Detection**: Instead of discovering errors one by one, we can now query:
    
    ```
    {service=~".*-service"} |= "ERROR" | json | line_format "{{.message}}"
    
    ```
    
    And spot patterns in failures across our entire ecosystem.
    
3. **Performance Monitoring**: We can track slow queries and API response times:
    
    ```
    {service="ticket-service"} |~ "response_time.*[5-9][0-9]{2,}ms"
    
    ```
    

## The Human Story: Developer Experience Transformed

### Before: The Midnight Detective Work

```bash
# The old way - jumping between containers
docker exec -it gateway_php tail -f storage/logs/laravel.log
# ... wait, the error might be in user service
docker exec -it user_php tail -f storage/logs/laravel.log
# ... actually, let me check ticket service too
docker exec -it ticket_php tail -f storage/logs/laravel.log

```

### After: The Zen of Centralized Logs

```
# Open Grafana dashboard
# Type: {service=~".*-service"} |= "user_id: 12345"
# See entire user journey in one view

```

The transformation in developer productivity has been remarkable. Our team went from dreading debugging sessions to actually enjoying the process of solving problems.

## Technical Highlights: What Makes This Special

### Smart Log Processing

- **Automatic metadata injection** - Service name, version, environment
- **Correlation ID tracking** - Follow requests across service boundaries
- **User context enrichment** - Know who triggered what action

### Scalable Architecture

- **Loki's label-based indexing** - Fast queries without full-text search overhead
- **JSON structured logs** - Rich metadata without parsing complexity
- **Docker-native collection** - No agent installation required

### Beautiful Visualizations

- **Service health dashboards** - At-a-glance system status
- **Error rate monitoring** - Spot issues before they escalate
- **Request flow tracing** - Visualize microservice interactions

## Lessons Learned: The Real Talk

### What Worked Brilliantly

- **Start simple**: We began with just the ticket service and gradually expanded
- **JSON everything**: Structured logs made querying effortless
- **Correlation IDs**: Game-changer for tracing requests across services
- **Docker labels**: Elegant way to route logs without code changes

### What We'd Do Differently

- **Alert fatigue is real**: Start with fewer, more meaningful alerts
- **Storage planning**: Logs can grow faster than you think - plan retention policies early
- **Team training**: Invest time in teaching the team LogQL (Loki's query language)

### Pro Tips for Your Implementation

1. **Label strategically** - Too many labels can hurt Loki's performance
2. **Use correlation IDs** - They're your debugging superpower
3. **Start with one service** - Prove the concept before going full-scale
4. **Plan for volume** - Production logs can be surprisingly large

## Conclusion: The Journey Continues

Implementing the PLG stack transformed how we understand and debug our microservice architecture. What started as a technical solution became a cultural shift - from reactive fire-fighting to proactive system understanding.

The best part? We did this with open-source tools, no vendor lock-in, and a solution that scales with our growth.

**If you're drowning in microservice logs**, consider the PLG stack. Your 2 AM self will thank you!

---

## Quick Start Guide

Here's the minimal setup:

1. **Add structured logging to Laravel**:
    
    ```php
    // In config/logging.php
    'centralized' => [
        'driver' => 'monolog',
        'formatter' => Monolog\\Formatter\\JsonFormatter::class,
        // ... processors for metadata
    ],
    
    ```
    
2. **Label your Docker containers**:
    
    ```yaml
    services:
      your-service:
        labels:
          - "service=your-service-name"
    
    ```
    
3. **Deploy PLG stack with docker-compose**:
    
    ```yaml
    # Basic PLG setup
    loki:
      image: grafana/loki:latest
      ports: ["3100:3100"]
    
    grafana:
      image: grafana/grafana:latest
      ports: ["3001:3000"]
    
    promtail:
      image: grafana/promtail:latest
      # ... configuration for log collection
    
    ```
    

**Happy logging!**

---

*Written by a developer who's been there, debugged that, and lived to tell the tale. May your logs be structured and your queries be fast!*